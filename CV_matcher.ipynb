{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZczYfah5Xx30",
        "outputId": "22e012be-d060-4be5-d0a4-c805325c4287"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (5.29.0)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (3.4.1)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.11/dist-packages (1.11.0)\n",
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.11/dist-packages (3.0.1)\n",
            "Requirement already satisfied: docx2txt in /usr/local/lib/python3.11/dist-packages (0.9)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: PyMuPDF in /usr/local/lib/python3.11/dist-packages (1.25.5)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.115.12)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio) (0.5.0)\n",
            "Requirement already satisfied: gradio-client==1.10.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.10.0)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.30.2)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.18)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.2.1)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.4)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.11.9)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.46.2)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.13.2)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.3)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.13.2)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.34.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.0->gradio) (2025.3.2)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.0->gradio) (15.0.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.51.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.15.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.4.26)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install gradio sentence-transformers faiss-cpu PyPDF2 docx2txt requests PyMuPDF\n",
        "with gr.Blocks() as app:\n",
        "    gr.Markdown(\"## üìÑ CV Matcher App\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DXoNh65GX3AR",
        "outputId": "7321a742-5a6b-4b3f-c92e-98ea5dfe0b79"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import gradio as gr\n",
        "import numpy as np\n",
        "import torch\n",
        "import requests\n",
        "import faiss\n",
        "import docx2txt\n",
        "import PyPDF2\n",
        "from transformers import AutoTokenizer, AutoModel"
      ],
      "metadata": {
        "id": "jvIgY9UtYca8"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_text_from_file(file_path):\n",
        "    ext = os.path.splitext(file_path)[1].lower()\n",
        "\n",
        "    if ext == \".pdf\":\n",
        "        try:\n",
        "            with open(file_path, \"rb\") as f:\n",
        "                reader = PyPDF2.PdfReader(f)\n",
        "                return \" \".join([page.extract_text() or \"\" for page in reader.pages])\n",
        "        except:\n",
        "            return \"[Error extracting PDF text]\"\n",
        "\n",
        "    elif ext == \".docx\":\n",
        "        try:\n",
        "            return docx2txt.process(file_path)\n",
        "        except:\n",
        "            return \"[Error extracting DOCX text]\"\n",
        "\n",
        "    else:\n",
        "        return \"[Unsupported file type]\"\n"
      ],
      "metadata": {
        "id": "HkrWtbeSYiPH"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "MODEL_NAME = \"thenlper/gte-small\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "model = AutoModel.from_pretrained(MODEL_NAME)\n",
        "\n",
        "def get_embeddings(texts, max_length=512):\n",
        "    if isinstance(texts, str):\n",
        "        texts = [texts]\n",
        "    final_embeddings = []\n",
        "    for text in texts:\n",
        "        tokens = tokenizer.tokenize(text)\n",
        "        chunks = [tokens[i:i + max_length] for i in range(0, len(tokens), max_length)]\n",
        "        chunk_embeddings = []\n",
        "        for chunk in chunks:\n",
        "            input_ids = tokenizer.convert_tokens_to_ids(chunk)\n",
        "            input_ids = torch.tensor([input_ids])\n",
        "            with torch.no_grad():\n",
        "                output = model(input_ids=input_ids)\n",
        "                embedding = output.last_hidden_state.mean(dim=1)\n",
        "                chunk_embeddings.append(embedding)\n",
        "        if chunk_embeddings:\n",
        "            avg_embedding = torch.stack(chunk_embeddings).mean(dim=0)\n",
        "            final_embeddings.append(avg_embedding.squeeze(0).numpy())\n",
        "        else:\n",
        "            final_embeddings.append(np.zeros(model.config.hidden_size))\n",
        "    return np.array(final_embeddings)\n"
      ],
      "metadata": {
        "id": "yiOr08BiYtyR"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def create_faiss_index(vectors):\n",
        "    try:\n",
        "        dim = vectors[0].shape[0]\n",
        "        index = faiss.IndexFlatL2(dim)\n",
        "        index.add(np.array(vectors).astype(\"float32\"))\n",
        "        return index\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error creating FAISS index: {e}\")\n",
        "        return None\n",
        "\n",
        "def search_similar_cvs(query_vector, index, k=3):\n",
        "    try:\n",
        "        query_vector = np.array([query_vector]).astype(\"float32\")\n",
        "        distances, indices = index.search(query_vector, k)\n",
        "        return indices[0].tolist()\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error searching index: {e}\")\n",
        "        return []\n"
      ],
      "metadata": {
        "id": "lj0ymK2CY0HU"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GROQ_API_KEY = \"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\"\n",
        "\n",
        "def summarize_match(job_description, cv_names, cv_snippets):\n",
        "    if not GROQ_API_KEY:\n",
        "        return \"‚ùå GROQ_API_KEY not set.\"\n",
        "\n",
        "    try:\n",
        "        job_description = job_description.strip()[:800] or \"[No description provided]\"\n",
        "        cv_snippets = [(text.strip()[:700] or \"[No content]\") for text in cv_snippets]\n",
        "        cv_names = [name[:60] for name in cv_names]\n",
        "\n",
        "        cv_section = \"\"\n",
        "        for i, (name, snippet) in enumerate(zip(cv_names, cv_snippets), start=1):\n",
        "            cv_section += f\"\\n{i}. {name}:\\n{snippet}\\n\"\n",
        "\n",
        "        prompt = f\"\"\"\n",
        "You are an AI recruitment assistant helping to evaluate candidate CVs for a job opening.\n",
        "\n",
        "Below is the job description, followed by {len(cv_names)} candidate CV summaries.\n",
        "\n",
        "Your job is to:\n",
        "- Analyze each candidate's relevance based on their technical skills, tools, and experience\n",
        "- Be honest: clearly state if a candidate is a good fit or not\n",
        "- Avoid generic praise unless it's supported by actual content\n",
        "{\"- Rank the candidates based on fit if more than one is provided.\" if len(cv_names) > 1 else \"\"}\n",
        "\n",
        "### Job Description:\n",
        "{job_description}\n",
        "\n",
        "### Candidate CVs:{cv_section}\n",
        "\"\"\".strip()\n",
        "\n",
        "        if len(prompt) > 8000:\n",
        "            prompt = prompt[:8000]\n",
        "\n",
        "        response = requests.post(\n",
        "            url=\"https://api.groq.com/openai/v1/chat/completions\",\n",
        "            headers={\n",
        "                \"Authorization\": f\"Bearer {GROQ_API_KEY}\",\n",
        "                \"Content-Type\": \"application/json\"\n",
        "            },\n",
        "            json={\n",
        "                \"model\": \"llama3-8b-8192\",\n",
        "                \"messages\": [\n",
        "                    {\"role\": \"system\", \"content\": \"You are a helpful recruitment assistant.\"},\n",
        "                    {\"role\": \"user\", \"content\": prompt}\n",
        "                ],\n",
        "                \"temperature\": 0.4\n",
        "            },\n",
        "            timeout=30\n",
        "        )\n",
        "        response.raise_for_status()\n",
        "        return response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        return f\"‚ùå Groq API error: {e}\"\n",
        "    except Exception as e:\n",
        "        return f\"‚ùå Unexpected error: {e}\"\n",
        "        # At the end of your notebook or script\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "PHHyWlLLY8fQ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv_texts = []\n",
        "cv_names = []\n",
        "cv_vectors = []\n",
        "faiss_index = None\n",
        "\n",
        "def upload_cvs(files):\n",
        "    global cv_texts, cv_names, cv_vectors, faiss_index\n",
        "    if len(files) > 10:\n",
        "        return \"‚ùå Limit exceeded: Max 10 CVs.\"\n",
        "\n",
        "    # Remove duplicates\n",
        "    unique_files = []\n",
        "    seen = set()\n",
        "    for f in files:\n",
        "        if f.name not in seen:\n",
        "            seen.add(f.name)\n",
        "            unique_files.append(f)\n",
        "    files = unique_files\n",
        "\n",
        "    cv_texts = [extract_text_from_file(f) for f in files]\n",
        "    cv_names = [f.name for f in files]\n",
        "    cv_vectors = get_embeddings(cv_texts)\n",
        "\n",
        "    if cv_vectors is None or np.array(cv_vectors).size == 0:\n",
        "        return \"‚ùå No valid CVs.\"\n",
        "\n",
        "    faiss_index = create_faiss_index(cv_vectors)\n",
        "    return f\"‚úÖ Uploaded and indexed {len(files)} CV(s).\"\n",
        "\n",
        "def match_jd(jd_text, match_mode):\n",
        "    if faiss_index is None:\n",
        "        return \"‚ùå Please upload CVs first.\"\n",
        "    if not jd_text.strip():\n",
        "        return \"‚ö†Ô∏è Job description is empty.\"\n",
        "\n",
        "    jd_vector = get_embeddings([jd_text])[0]\n",
        "    if match_mode == \"Top 3 Matches\":\n",
        "        indices = search_similar_cvs(jd_vector, faiss_index, k=3)\n",
        "    else:\n",
        "        indices = list(range(len(cv_names)))\n",
        "\n",
        "    seen = set()\n",
        "    unique_indices = []\n",
        "    for i in indices:\n",
        "        if cv_names[i] not in seen:\n",
        "            seen.add(cv_names[i])\n",
        "            unique_indices.append(i)\n",
        "\n",
        "    matched = [cv_names[i] for i in unique_indices]\n",
        "    texts = [cv_texts[i] for i in unique_indices]\n",
        "    summary = summarize_match(jd_text, matched, texts)\n",
        "    title = f\"‚úÖ Matching {len(matched)} CVs:\"\n",
        "    return f\"{title}\\n\\n\" + \"\\n\".join(matched) + f\"\\n\\nüìù Summary:\\n{summary}\"\n",
        "\n",
        "def clear_data():\n",
        "    global cv_texts, cv_names, cv_vectors, faiss_index\n",
        "    cv_texts, cv_names, cv_vectors, faiss_index = [], [], [], None\n",
        "    return \"üßπ Cleared.\"\n",
        "\n",
        "import gradio as gr\n",
        "\n",
        "with gr.Blocks() as app:\n",
        "    gr.Markdown(\"## üìÑ CV Matcher App\")\n",
        "\n",
        "    # Upload section\n",
        "    file_input = gr.File(file_types=[\".pdf\", \".docx\"], file_count=\"multiple\", label=\"üì§ Upload CVs\")\n",
        "    upload_button = gr.Button(\"üìÅ Upload & Index\")\n",
        "    upload_status = gr.Textbox(label=\"Upload Status\")\n",
        "\n",
        "    # Job description input\n",
        "    jd_input = gr.Textbox(label=\"üìã Paste Job Description\", lines=6, placeholder=\"Paste JD here...\")\n",
        "\n",
        "    # Matching mode (Top 3 or All)\n",
        "    match_mode = gr.Radio([\"Top 3 Matches\", \"All Uploaded CVs\"], value=\"Top 3 Matches\", label=\"Matching Mode\")\n",
        "\n",
        "    match_button = gr.Button(\"üîç Match CVs\")\n",
        "    result_output = gr.Textbox(label=\"Results\", lines=20)\n",
        "\n",
        "    # Clear session\n",
        "    clear_button = gr.Button(\"üßπ Clear All\")\n",
        "    clear_status = gr.Textbox(label=\"Clear Status\")\n",
        "\n",
        "    # Click actions\n",
        "    upload_button.click(upload_cvs, inputs=[file_input], outputs=[upload_status])\n",
        "    match_button.click(match_jd, inputs=[jd_input, match_mode], outputs=[result_output])\n",
        "    clear_button.click(clear_data, inputs=[], outputs=[clear_status])\n",
        "\n",
        "# Launch the app\n",
        "app.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 650
        },
        "id": "tyJPRHqUZNdn",
        "outputId": "d857fdc5-38aa-4635-e634-23b95930e9d4"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://9b57660317b88342d5.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://9b57660317b88342d5.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hPiwQFwAbZFs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}